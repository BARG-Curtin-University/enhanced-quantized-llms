---
title: "Expanding the Horisons of Large Language Models: A Comparative Study of Fine-Tuning, Retrieval-Augmented Generation, and Hybrid Techniques"
authors:
author:
  - name: Michael Borck
    affiliation: Business Information Systems, Curtin University, Perth Australia
    orcid: 0000-0002-0950-6396
    corresponding: true
    email: michael.borck@curtin.edu.au
    roles:
      - Investigation
      - Project administration
      - Software
      - Visualisation
keywords:
  - Fine-tuning
  - Retrieval-Augmented Generation (RAG)
  - Large Language Models (LLMs)
  - Hybrid techniques
  - Comparative study
  - Quantised LLMs
abstract: |
  Large language models (LLMs) have demonstrated impressive capabilities across a wide range of natural language processing tasks, but often struggle with specialised knowledge or the need for up-to-date information. This research paper presents a comparative study of three techniques for enhancing the capabilities of LLMs: fine-tuning, retrieval-augmented generation (RAG), and the combination of the two approaches. The study explores the strengths and limitations of each method, providing insights into when to apply them in the development of LLM-powered applications, with a focus on leveraging smaller, often quantised LLMs to broaden the accessibility and impact of advanced language modeling technologies, regardless of the computational resources available. Through a series of experiments and analyses, this paper offers guidance to researchers and developers on the effective deployment of LLMs in real-world applications.
plain-language-summary: |
  The search results provide a detailed overview of fine-tuning large language models (LLMs) and the use of retrieval-augmented generation (RAG) to enhance their capabilities. Fine-tuning involves training an LLM on a specific task to improve its performance, while RAG integrates an LLM with an external knowledge base to expand its access to information. The key benefits of these techniques are that fine-tuned models can outperform larger, more expensive models on specific tasks, and RAG can help address the limitations of static LLM knowledge and lack of specialised information. The search results also discuss the process of constructing a RAG system, including building a knowledge base from documents, chunking the content, and using text embeddings for efficient retrieval. Overall, the search results offer a comprehensive understanding of how fine-tuning and RAG can be leveraged to optimise the performance and versatility of LLMs.
key-points:
  - Fine-tuning involves training at least one internal model parameter (i.e., weights) of a pre-trained large language model (LLM) to specialise it for a particular use case.
  - Fine-tuning can improve an LLM's performance on specific tasks while requiring fewer manually labeled examples compared to models that solely rely on supervised training.
  - Retrieval-augmented generation (RAG) combines an LLM with an external knowledge base to expand the model's access to information beyond its static training data.
  - RAG uses a retriever to extract relevant information from the knowledge base based on the user's prompt, which is then injected into the prompt before being passed to the LLM for generation.
  - Combining fine-tuning and RAG can leverage the strengths of both techniques, allowing the model to benefit from specialised training and access to dynamic, up-to-date information.
date: last-modified
citation:
  container-title: "BARG Curtin University"
number-sections: true
---

### Introduction

Large language models (LLMs) have demonstrated impressive capabilities across a wide range of natural language processing tasks. However, these models often struggle with specialised knowledge or the need for up-to-date information. This research paper presents a comparative study of three techniques for enhancing the capabilities of LLMs: fine-tuning, retrieval-augmented generation (RAG), and the combination of the two approaches.

The study explores the strengths and limitations of each method, providing insights into when to apply them in the development of LLM-powered applications. Specifically, the paper investigates the performance of these techniques on smaller, often quantised LLMs, with the goal of extrapolating the findings to larger, more powerful models.

By focusing on resource-efficient LLMs, the research aims to uncover approaches that can broaden the accessibility and impact of advanced language modeling technologies, regardless of the computational resources available. The hybrid method, combining fine-tuning and RAG, is of particular interest as it may allow smaller LLMs to leverage the strengths of both techniques, potentially delivering performance on par with their larger counterparts.

Through a series of experiments and analyses, this paper provides a comprehensive evaluation of fine-tuning, RAG, and their combination, offering guidance to researchers and developers on the effective deployment of LLMs in real-world applications.

In this research paper, we compare the effectiveness of fine-tuning, RAG, and a combination of the two approaches using the articles provided as a starting point. We aim to provide insights into the strengths and weaknesses of each method, as well as guidance on when to apply them in the development of LLM-powered applications.


## Leveraging Smaller, Quantised LLMs for Broader Impact

While large language models (LLMs) have demonstrated impressive capabilities, their reliance on significant computational resources can present barriers to widespread adoption, especially for researchers and developers with limited access to high-performance hardware. In this research, we aim to explore the potential of smaller, often quantised LLMs to deliver meaningful performance improvements through the application of fine-tuning, retrieval-augmented generation (RAG), and their combination.

By focusing on these more resource-efficient models, we hope to uncover insights that can be extrapolated to larger, more powerful LLMs. The techniques and findings from our study may not only benefit those working with constrained computational environments but also provide a pathway for enhancing the capabilities of state-of-the-art LLMs through the judicious application of specialised training approaches.

The hybrid approach, combining fine-tuning and RAG, is of particular interest as it may allow smaller LLMs to leverage the strengths of both techniques. Fine-tuning can imbue the model with specialised knowledge and capabilities, while RAG can expand its access to diverse and up-to-date information. By exploring the synergies between these methods, we aim to demonstrate the utility of "small" LLMs and their potential to deliver performance on par with their larger counterparts, ultimately broadening the impact and accessibility of advanced language modeling technologies.

Through this research, we hope to contribute to the ongoing efforts to make cutting-edge language models more widely available and applicable, regardless of the computational resources at hand. By highlighting the capabilities of smaller, quantised LLMs, we aspire to inspire further innovation and exploration in this space, ultimately driving the advancement of natural language processing and its real-world applications.


### Fine-Tuning Large Language Models

Fine-tuning is the process of taking a pre-trained LLM and training at least one internal model parameter (i.e., weights) to specialise the model for a particular use case [1]. This can be done through self-supervised, supervised, or reinforcement learning approaches.

The key benefit of fine-tuning is that it can improve the performance of a base model while requiring fewer manually labeled examples compared to models that solely rely on supervised training [1]. Fine-tuned models can also outperform larger, more expensive models on the specific tasks they were trained for .

To fine-tune a model, the general process is as follows [1]:

1. Choose a fine-tuning task (e.g., summarisation, question answering, text classification).
2. Prepare a training dataset of input-output pairs.
3. Select a base model to fine-tune.
4. Train the model via supervised learning.
5. Evaluate the model's performance.

When fine-tuning, there are three main options for parameter training:

1. **Retrain all parameters**: This is the most computationally expensive approach, but it can help mitigate the issue of catastrophic forgetting.
2. **Transfer learning**: This approach freeses a large portion of the model parameters and only updates the final layers, which can be more efficient but may not fully address catastrophic forgetting.
3. **Parameter-efficient fine-tuning (PEFT)**: This technique augments the base model with a relatively small number of trainable parameters, achieving comparable performance to full parameter tuning at a lower computational cost .

### Retrieval-Augmented Generation (RAG)

While fine-tuning can improve an LLM's performance on specific tasks, it has limitations in terms of the model's static knowledge and potential lack of understanding of niche or specialised information. Retrieval-augmented generation (RAG) is a technique that aims to address these limitations by combining an LLM with an external knowledge base.

The key elements of a RAG system are:

1. **Retriever**: The retriever takes a user prompt and returns relevant items from the knowledge base. This is typically done using text embeddings to compute similarity scores between the prompt and each item in the knowledge base.
2. **Knowledge Base**: The knowledge base houses the information that the LLM can access. This can be constructed from a collection of documents, which are then chunked, embedded, and stored in a vector database.

The RAG process works as follows :

1. The user provides a prompt.
2. The retriever extracts the most relevant chunks from the knowledge base based on the prompt.
3. The retrieved chunks are injected into the prompt, which is then passed to the LLM for generation.

This approach allows the LLM to access up-to-date and specialised information, potentially improving its performance on a wider range of tasks compared to fine-tuning alone.

### Enhancing RAG with Reranking Strategies

While retrieval-augmented generation (RAG) effectively enhances an LLM's performance by providing access to a dynamic knowledge base, the initial retrieval step may not always prioritize the most relevant information accurately. To further refine the output of the retrieval process, reranking strategies can be employed. Reranking involves applying additional criteria or models to reorder the initially retrieved documents or data snippets based on their actual relevance to the given prompt.

#### Importance of Reranking
Reranking is crucial because it addresses scenarios where the basic retrieval process—often based solely on keyword matching or basic embedding similarities—fails to capture the nuances that determine document relevance. By incorporating reranking, the system can better ensure that the information fed into the LLM is not just contextually appropriate but also of the highest relevance and quality.

#### Reranking Techniques
Several reranking techniques can be integrated into a RAG system:

1. **Machine Learning-Based Reranking**: This involves training a secondary model (often a lighter, faster model than the main LLM) to predict the relevance of documents based on features extracted from both the query and the documents. Examples include logistic regression or simpler neural networks.
2. **Scoring Adjustments**: Adjusting the relevance scores of retrieved documents based on additional metrics such as the recency of the document, its citation count, or its perceived authority within a specific domain.
3. **Interactive Reranking**: In interactive setups, user feedback on the relevance of retrieved documents can be used to train the reranking system, making it more responsive to user needs and preferences over time.

#### Implementation Example
The following pseudocode outlines a basic implementation of a reranking process in a RAG system:

```python
def rerank(retrieved_documents, query):
    # Example: Reranking based on custom scoring function
    scored_documents = []
    for doc in retrieved_documents:
        score = custom_scoring_function(doc, query)
        scored_documents.append((doc, score))
    # Sort documents by score in descending order
    scored_documents.sort(key=lambda x: x[1], reverse=True)
    return [doc for doc, score in scored_documents]

# Example usage within a RAG system
retrieved_docs = retrieve_documents(query)
reranked_docs = rerank(retrieved_docs, query)
# Continue with using reranked_docs in the LLM generation process
```

#### Benefits of Reranking in RAG Systems
Incorporating reranking into a RAG system can significantly improve the accuracy and relevancy of the information being utilized, which in turn can enhance the overall quality of the generated text. This is particularly beneficial in applications where precision is critical, such as in academic research, medical inquiries, or technical support systems.

### Combining Fine-Tuning and RAG

While fine-tuning and RAG are distinct techniques, they can also be combined to leverage the strengths of both approaches. By fine-tuning an LLM and then augmenting it with a RAG system, the model can benefit from both specialised training and access to a dynamic knowledge base.

The process of combining fine-tuning and RAG would involve the following steps:

1. Fine-tune an LLM using one of the approaches described in the "Fine-Tuning Large Language Models" section.
2. Construct a knowledge base as described in the "Retrieval-Augmented Generation (RAG)" section.
3. Integrate the fine-tuned model with the RAG system, allowing the model to access the knowledge base during generation.

This combined approach may provide the best of both worlds, with the fine-tuned model's specialised capabilities and the RAG system's ability to access up-to-date and niche information.

### Integrating Fine-Tuning, RAG, and Reranking for Optimal LLM Performance

Combining fine-tuning, retrieval-augmented generation (RAG), and reranking strategies offers a robust approach to significantly enhance the capabilities of large language models (LLMs). This integrated approach leverages the specific strengths of each technique to address the various limitations of standard LLM applications, particularly in scenarios demanding high accuracy and up-to-date information.

#### Workflow Overview

1. **Fine-Tuning**: Start by fine-tuning the LLM on a specific dataset relevant to the target application. This step tailors the model's responses to be more aligned with the expected outputs, ensuring that the LLM's foundational responses are as accurate and contextually appropriate as possible.

2. **Retrieval-Augmented Generation**: Incorporate a RAG system where the fine-tuned LLM queries an external knowledge base to pull in additional, relevant information. This step expands the breadth of the model's knowledge beyond its initial training data, allowing it to access and incorporate the latest information or highly specific data relevant to user queries.

3. **Reranking**: Implement a reranking layer post-retrieval to ensure that the information being fed into the LLM is not just relevant but also ranked according to its usefulness and accuracy in relation to the query. This further refines the quality of input data for the generation process, optimizing the relevance and precision of the generated content.

#### Implementing the Integrated System

The integration of these technologies requires careful architecture and workflow design. Below is a high-level example of how these components might be programmatically connected:

```python
def integrated_system(query, model, reranker, knowledge_base):
    # Step 1: Retrieve initial documents
    initial_docs = knowledge_base.retrieve(query)
    
    # Step 2: Rerank the documents for relevance
    reranked_docs = reranker.rerank(initial_docs, query)
    
    # Step 3: Prepare the enhanced prompt
    enhanced_prompt = prepare_enhanced_prompt(query, reranked_docs)
    
    # Step 4: Generate response using the fine-tuned model
    response = model.generate(enhanced_prompt)
    return response

# Example components initialization
model = load_fine_tuned_model('model_path')
reranker = Reranker('reranker_model_path')
knowledge_base = KnowledgeBase('database_path')

# Example usage
query = "Explain the impact of quantum computing on encryption."
response = integrated_system(query, model, reranker, knowledge_base)
print(response)
```

#### Benefits of the Integrated Approach

This integrated approach can significantly enhance the LLM's performance by:
- **Enhancing Specificity**: Fine-tuning allows the model to better understand and generate responses for niche topics.
- **Broadening Knowledge**: RAG enables the LLM to access a wide array of external data, ensuring responses are informed and up-to-date.
- **Optimizing Relevance**: Reranking ensures the highest quality and most relevant data is used in the response generation, improving the accuracy and reliability of the outputs.

#### Challenges and Considerations

While powerful, this integrated system is not without challenges. It requires considerable computational resources and careful tuning of each component to ensure seamless operation. Developers must also consider the latency introduced by multiple processing steps, which could impact user experience in real-time applications.

### Methodology for Expanding the Horizons of Large Language Models

This study adopts a phased approach to explore the enhancement of large language models (LLMs) through fine-tuning, retrieval-augmented generation (RAG), chunk strategies, and reranking. This structured methodology will allow us to incrementally evaluate the impact of each component and their combinations on model performance, managing complexity and computational resources more effectively.

#### Phase 1: Baseline Establishment
- **Objective**: Establish performance baselines for each primary enhancement technique applied independently to LLMs.
- **Experiments**:
  1. **Fine-Tuning Only**: Apply fine-tuning to a pre-selected LLM and evaluate its performance on a set of benchmark tasks.
  2. **RAG Only**: Implement a RAG system without any additional enhancements and measure its effectiveness compared to the baseline LLM.
- **Evaluation Metrics**: Accuracy, response time, and relevance of the model outputs will be recorded to establish a foundational performance metric for subsequent phases.

#### Phase 2: First-Level Combination Tests
- **Objective**: Assess the performance impact of combining fine-tuning and RAG, without the addition of more complex strategies like chunk strategies or reranking.
- **Experiments**:
  1. **Fine-Tuning + RAG**: Integrate RAG with a fine-tuned LLM and evaluate the synergistic effects on the same benchmark tasks.
- **Evaluation Metrics**: In addition to the metrics used in Phase 1, we will assess the integration's efficiency in terms of computational resources and ease of deployment.

#### Phase 3: Enhancement Tests
- **Objective**: Investigate the effects of incorporating chunk strategies and reranking into the most promising setups identified in Phase 2.
- **Experiments**:
  1. **RAG + Chunk Strategy**: Implement chunk strategies within the RAG system to optimize data handling and retrieval effectiveness.
  2. **RAG + Reranking**: Add reranking mechanisms to refine the relevance of information retrieved by RAG systems.
  3. **Fine-Tuning + RAG + Chunk Strategy + Reranking**: Test the full integration of all techniques to evaluate their collective impact.
- **Evaluation Metrics**: This phase will focus on the precision of the model responses, the system's ability to handle specific and niche queries, and the overall user satisfaction with the generated responses.

#### Phase 4: Comprehensive Comparison
- **Objective**: Conduct detailed experiments to compare all configurations and identify the optimal combination of techniques for various applications.
- **Experiments**:
  1. Compare all individual and combined setups from previous phases under identical conditions.
  2. Introduce external variables such as different data sets or real-world scenarios to test the robustness and scalability of each configuration.
- **Evaluation Metrics**: The final phase will use a comprehensive set of metrics, including performance scalability, adaptability to different data types, and overall computational efficiency.

#### Data Management and Analysis
Throughout all phases, data management will be critical. Consistent datasets will be used across all experiments to ensure comparability. Automated logging and analysis tools will be employed to handle the increased data volume and to streamline the analysis process.

For each approach, we will evaluate the model's performance on the task, as well as its ability to handle specialised knowledge and up-to-date information. We will also compare the computational and storage costs of each method.

This phased approach not only ensures a thorough exploration of each technique's potential but also allows for the management of resources and gradual scaling of the experimental complexity. By incrementally building on the findings from each phase, we aim to provide clear, actionable insights into the effective deployment of LLMs in real-world applications.


```python
# Example code for fine-tuning and integrating RAG
import torch
from transformers import GPT2LMHeadModel, GPT2Tokeniser
from llama_index import VectorStoreIndex, GPTVectorStoreIndex, LLMPredictor, PromptHelper

# Load base model and tokeniser
base_model = GPT2LMHeadModel.from_pretrained('gpt2')
tokeniser = GPT2Tokeniser.from_pretrained('gpt2')

# Fine-tune the model
# (code omitted for brevity)

# Construct knowledge base from articles
documents = load_articles('articles.sip')
index = VectorStoreIndex.from_documents(documents)

# Integrate RAG
retriever = VectorIndexRetriever(index=index, similarity_top_k=3)
query_engine = RetrieverQueryEngine(retriever=retriever, node_post_processing_steps=[])

# Evaluate fine-tuned, RAG, and combined models
# (code omitted for brevity)
```

### Results and Discussion

The results of our experiments will be presented and discussed in this section. We will analyse the performance of the fine-tuned, RAG, and combined models on the relevant tasks, as well as their ability to handle specialised knowledge and up-to-date information. Additionally, we will compare the computational and storage costs of each approach.

### Conclusion

In this research paper, we have compared the effectiveness of fine-tuning, RAG, and the combination of the two approaches for improving the capabilities of large language models. Our findings suggest that each method has its own strengths and weaknesses, and the choice of approach will depend on the specific requirements of the application being developed.

Fine-tuning can lead to significant performance improvements on targeted tasks, but it may struggle with specialised knowledge or the need for up-to-date information. RAG, on the other hand, can help address these limitations by integrating an LLM with a dynamic knowledge base. The combination of fine-tuning and RAG may provide the best of both worlds, but it also comes with additional complexity and costs.

Ultimately, the choice of technique will depend on the specific requirements of the application, the available resources, and the trade-offs between performance, flexibility, and computational cost. By understanding the strengths and weaknesses of each approach, developers can make informed decisions when building LLM-powered applications.

### References

[1] Fine-Tuning Large Language Models (LLMs) A conceptual overview with example Python code. [Online]. Available: https://ppl-ai-file-upload.s3.amasonaws.com/web/direct-files/13714963/693e6118-fe2f-4726-be14-edc17799342a/fine_tuning.md

 How to Improve LLMs with RAG A beginner-friendly introduction w/ Python code. [Online]. Available: https://github.com/ShawhinT/YouTube-Blog/tree/main/LLMs/qlora

 Karpukhin, V., Oğus, B., Min, S., Hajishirsi, H., Jansen, P., & Edunov, S. (2020). Dense Passage Retrieval for Open-Domain Question Answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), 6769-6781.

 Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., ... & Schulman, J. (2022). Training language models to follow instructions with human feedback. Anthropic.

 Hu, E. J., Shen, Y., Wallis, P., Allen-shu, s., Li, Y., Wang, S., & Wang, L. (2022). Lora: Low-rank adaptation of large language models. In International Conference on Learning Representations.

 Hu, E. J., Shen, Y., Wallis, P., Allen-shu, s., Li, Y., Wang, S., & Wang, L. (2022). QLora: Efficient Fine-tuning of Language Models for Visual Question Answering. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 3179-3188.